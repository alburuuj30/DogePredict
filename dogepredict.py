# -*- coding: utf-8 -*-
"""DogePredict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vSkES1-3FgAblWcronGd6RGhcxbWFciU

* Nama Lengkap : Fajar Maulana Thaariq A
* Username : alburuuj
* Email : fajarm643@gmail.com
* No Telp : +6289619785254
* Kota Domisili : Kab. Semarang
* Tempat Lahir : Kab. Boyolali
* Tanggal Lahir : 30 Juni 2001
* Pendidikan Terakhir : SMA
* Pekerjaan / Profesi saat ini : Pelajar / Mahasiswa
* Perusahaan/ Institusi saat ini : Institut Teknologi Telkom Purwokerto
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf

from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score
from sklearn.preprocessing import MinMaxScaler

from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor

from sklearn.metrics import mean_squared_error

df = pd.read_csv('coin_Dogecoin.csv')
df

"""Daftar Variable yang tersedia :


*   Name
*   Symbol
*   Date
*   High
*   Low
*   Open
*   Close
*   Volume
*   Marketcap









"""

# Checking missing values on data
df.info()
print('Total missing value in the dataframe:', df.isnull().sum().sum(), 'records')

"""Setelah kita cek, Data tidak memiliki Missing Values pada dataset yang kita gunakan"""

df.describe()

""" **catatan informasi**
 * **count** merupakan jumlah sample data pada tiap kolom
 * **mean** yang berarti nilai rata - rata pada data di tiap kolom
 * **std** yaitu standar deviasi pada tiap kolom
 * **min** nilai minimum atau yang terkecil pada tiap kolom
 * **25%** adalah kuartil pertama atau Q1
 * **50%** adalah Kuartil kedua atau Q2 dan juga bisa disebut dengan median (nilai tengah)
 * **75%** adalah kuartil ketiga atau Q3
 * **max** nilai maksimum atau nilai terbesar dari tiap kolom
"""

numeric_features = df.select_dtypes(include=np.number).columns.tolist()
plt.figure(figsize=(15, 9))

for i, col in enumerate(numeric_features):
  plt.subplot(3,3,i+1)
  df.boxplot(column=col)

"""Dari hasil diatas, beberapa kolom terdapat banyak outlier. outlier dapat diatasi dengan menerapkan methode IQR (metod penghapusan data yang berada pada luar interquartil)"""

Q1 = df.quantile(.25)
Q3 = df.quantile(.75)
IQR = Q3 - Q1
bot_lim = Q1 - 1.5 * IQR
top_lim = Q3 + 1.5 * IQR
df = df[~((df < bot_lim) | (df > top_lim)).any(axis=1)]
df.head()

"""# Univariate Analysis
analisa yang berfokus pada satu variabel yang bertujuan untuk mengidentifikasi dan mengetahui dari karakteristik yang dimiliki

Pada kali ini kita akan memilih fitur Close sebagai acuan dari analisa yang nanti akan dicari beberapa korelasi data pada fitur ini. 
"""

df.hist(bins=50, figsize=(15, 10))
plt.show()

"""# Multivariate Analysis
Pada analisa sebelumnya kita hanya menganalisa berdasarkan 1 variable saja, pada analisa kali ini kita akan menganalisa serta membandingkan variable dengan variable yang lain
"""

sns.pairplot(df, diag_kind = 'kde')
plt.show()

"""Dari visualisasi diatas, yang memiliki korelasi dengan fitur Close daintaranya fitur High, Low, Open, dan Marketcap"""

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

df.drop(['Volume'], axis=1, inplace=True)
df

"""Pada vsiualisasi di atas memnunjukkan beberapa skor korelasi yang diperoleh pada tiap tiap kolom. Pada fitur High, Low, open, dan Marketcap memiliki skor korelasi yang paling besar. dibanding fitur volume yang memiliki nilai korelasi yang rendah

# Data Preparation
Next, kita akan menghapus beberapa kolom data yang mungkin sudah tidak kita gunakan lagi, dengan harapan agar tidak mengganggu model saat training dimulai
"""

df = df.drop(['SNo', 'Name', 'Symbol', 'Date', 'Marketcap'], axis=1)
df.head()

"""membagi dataset menjadi 2 bagian, data training dan testing"""

X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)

print('Total X_train:', len(X_train), 'records')
print('Total y_train:', len(y_train), 'records')
print('Total X_test:', len(X_test), 'records')
print('Total y_test:', len(y_test), 'records')

"""# Data Normalization
Untuk menormalisasikan data yang kita gunakan, kita akan menggunakan MinMaxScaler untuk penerapannya
"""

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

models = pd.DataFrame(columns=['train_mse', 'test_mse'], index=['KNN', 'SVR', 'RandomForest'])

"""# Modelling
Implementasi permodelan dengan menggunakan tuning hyperparameter. untuk mendapatkan performa terbaik dari beberapa model.

# KNN
"""

knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(x_train, y_train)

"""# SVR"""

svr = SVR(C=100000, gamma=0.003, kernel='rbf')                          
svr.fit(x_train, y_train)

"""# RandomForest"""

rf = RandomForestRegressor(n_estimators=6, max_depth=16)
rf.fit(x_train, y_train)

"""# Evaluasi Model"""

x_test = scaler.transform(x_test)

model_dict = {'KNN': knn, 'RandomForest': rf, 'SVR': svr}

for name, model in model_dict.items():
  models.loc[name, 'train_mse'] = mean_squared_error(y_true=y_train, y_pred=model.predict(x_train))
  models.loc[name, 'test_mse'] = mean_squared_error(y_true=y_test, y_pred=model.predict(x_test)) 

models

fig, ax = plt.subplots()
models.sort_values(by='test_mse', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

test_data = x_test.copy()
predictions = {'y_true':y_test}
for name, model in model_dict.items():
  predictions['prediction_' + name] = model.predict(test_data)
 
predictions = pd.DataFrame(predictions)
predictions
plt.show()